import torch
from ultralytics import YOLO
import os
import time
from datetime import datetime

def get_optimal_settings():
    """ç’°å¢ƒã«å¿œã˜ãŸæœ€é©è¨­å®šã‚’è‡ªå‹•æ±ºå®š"""
    if torch.cuda.is_available():
        device = 'cuda'
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        if gpu_memory_gb >= 12:
            batch_size = 32
            workers = 8
        elif gpu_memory_gb >= 8:
            batch_size = 24
            workers = 6
        elif gpu_memory_gb >= 6:
            batch_size = 16
            workers = 4
        else:
            batch_size = 12
            workers = 2
        
        gpu_capability = torch.cuda.get_device_capability(0)
        use_amp = gpu_capability[0] >= 7
        
        print(f"ğŸš€ GPU: {gpu_name} ({gpu_memory_gb:.1f}GB) | Batch: {batch_size} | AMP: {'ON' if use_amp else 'OFF'}")
        return device, batch_size, workers, use_amp
        
    else:
        device = 'cpu'
        cpu_count = os.cpu_count()
        
        if cpu_count >= 16:
            batch_size = 16
            workers = min(8, cpu_count // 2)
        elif cpu_count >= 12:
            batch_size = 12
            workers = min(6, cpu_count // 2)
        else:
            batch_size = 8
            workers = min(4, cpu_count // 2)
        
        print(f"ğŸ’» CPU: {cpu_count} cores | Batch: {batch_size}")
        return device, batch_size, workers, False

class SimpleTimer:
    """ã‚·ãƒ³ãƒ—ãƒ«å­¦ç¿’æ™‚é–“è¨ˆæ¸¬"""
    def __init__(self):
        self.start_time = None
        
    def start(self):
        self.start_time = time.time()
        print(f"â±ï¸ Started: {datetime.now().strftime('%H:%M:%S')}")
        
    def finish(self):
        if self.start_time is not None:
            total_time = time.time() - self.start_time
            minutes = int(total_time // 60)
            seconds = int(total_time % 60)
            print(f"â±ï¸ Finished: {datetime.now().strftime('%H:%M:%S')} | Duration: {minutes:02d}:{seconds:02d}")
            return total_time
        return 0

def main():
    timer = SimpleTimer()
    
    # ç’°å¢ƒè¨­å®š
    device, batch_size, workers, use_amp = get_optimal_settings()
    
    # GPUæœ€é©åŒ–
    if device == 'cuda':
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        torch.cuda.empty_cache()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
    model = YOLO('yolo11s.pt')
    print(f"ğŸ“¦ Model: YOLO11s loaded")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¢ºèª
    data_path = 'Custom_training/Annotation/quadcopter/data.yaml'
    if not os.path.exists(data_path):
        print(f"âŒ Dataset not found: {data_path}")
        return
    
    print(f"ğŸ“Š Dataset: {data_path}")
    
    # å­¦ç¿’è¨­å®š
    epochs = 30
    training_config = {
        'data': data_path,
        'epochs': epochs,
        'imgsz': 640,
        'batch': batch_size,
        'device': device,
        'workers': workers,
        'project': 'runs/train',
        'name': f'quad_nano_{"gpu" if device=="cuda" else "cpu"}_{batch_size}b_{epochs}ep_{datetime.now().strftime("%m%d_%H%M")}',
        'save_period': 10,
        'patience': 100,
        'verbose': False,  # YOLOã®è©³ç´°ãƒ­ã‚°ã‚’éè¡¨ç¤º
        'plots': True,
        'cache': 'ram' if device == 'cuda' else False,
    }
    
    if device == 'cuda':
        training_config.update({
            'amp': use_amp,
            'close_mosaic': 10,
            'copy_paste': 0.1,
            'mixup': 0.1,
        })
    
    print(f"ğŸ‹ï¸ Training: {epochs} epochs | Batch: {batch_size} | Device: {device}")
    
    try:
        timer.start()
        
        # å­¦ç¿’å®Ÿè¡Œ
        results = model.train(**training_config)
        
        # å­¦ç¿’å®Œäº†
        total_time = timer.finish()
        
        # çµæœè¡¨ç¤º
        print(f"âœ… Training completed successfully")
        
        # æ€§èƒ½ã‚µãƒãƒªãƒ¼
        epoch_time = total_time / epochs
        print(f"ğŸ“ˆ Performance: {epoch_time:.1f}s/epoch | {epochs/total_time*3600:.0f} epochs/hour")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        try:
            if hasattr(results, 'metrics') and hasattr(results.metrics, 'box'):
                metrics = results.metrics.box
                print(f"ğŸ“Š Results: mAP50={metrics.map50:.3f} | mAP50-95={metrics.map:.3f}")
        except:
            pass
        
        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
        best_model_path = os.path.join(results.save_dir, 'weights', 'best.pt')
        if os.path.exists(best_model_path):
            file_size_mb = os.path.getsize(best_model_path) / (1024 * 1024)
            print(f"ğŸ† Best model: {file_size_mb:.1f}MB | {best_model_path}")
        
        print(f"ğŸ“ Results: {results.save_dir}")
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Training interrupted")
        timer.finish()
    except RuntimeError as e:
        if "out of memory" in str(e):
            print(f"âŒ GPU OOM! Try batch size: {batch_size//2}")
        else:
            print(f"âŒ Error: {e}")
        timer.finish()
    except Exception as e:
        print(f"âŒ Error: {e}")
        timer.finish()
    finally:
        if device == 'cuda':
            torch.cuda.empty_cache()

if __name__ == '__main__':
    main()
